{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an\n",
    "# example of each.\n",
    "\"\"\"The diffrence between simple linear regression and the multiple linear regression is that simple linear \n",
    "regression has one independent variable and the multiple linear regression has more than one independent variable \n",
    "Simple linear regression involves a relationship between two variables, one independent variable  and one\n",
    " dependent variable . The model can be represented as \n",
    " y = mx + c, where c is the intercept, m is the slope coefficient.\n",
    "\n",
    " example= The simplest example is the total sales of any product  versus the price \n",
    "\n",
    "\n",
    "\n",
    "Multiple linear regression, on the other hand, involves a relationship between two or more independent \n",
    "variables (X1, X2, X3, …, Xn) and one dependent variable (Y). The model can be represented as \n",
    "Y = β0 + β1X1 + β2X2 + … + βn*Xn, where β0 is the intercept, β1, β2, …, βn are the slope \n",
    "coefficients\n",
    "\n",
    "An example of multiple linear regression can be to predict the predict the price of a house , the price of \n",
    "the house  id determined by various factors like locality , no of rooms , built up area etc\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in\n",
    "# a given dataset?\n",
    "\"\"\"Linear regression is a statistical technique used to model the relationship between a dependent variable and one \n",
    "or more independent variables. \n",
    "\n",
    "The following are the assumptions of linear regression:\n",
    "\n",
    "Linearity----> The relationship between the dependent variable and independent variables should be linear, which means \n",
    "that the relationship should be able to be represented by a straight line.\n",
    "\n",
    "Independence---->The observations used in the regression analysis should be independent of each other.\n",
    "\n",
    "Homoscedasticity---->The variance of the errors should be constant across all levels of the independent variable. \n",
    "In other words, the errors should be equally distributed across the range of the independent variable.\n",
    "\n",
    "Normality---->The error term should be normally distributed with a mean of zero.\n",
    "\n",
    "No multicollinearity------->There should be no high correlation between the independent variables in the model.\n",
    "\n",
    "\n",
    "\n",
    "Residual plot---->Plotting the residuals against the fitted values can help check whether the assumptions of linearity,\n",
    " independence, and homoscedasticity are met.\n",
    "\n",
    "QQ plot---->A quantile-quantile plot can help determine whether the error terms are normally distributed.\n",
    "\n",
    "Variance inflation factor (VIF)------->This can help identify the presence of multicollinearity by examining the correlation \n",
    "between the independent variables.\n",
    "\n",
    "Durbin-Watson test-----> This test helps check whether the residuals are autocorrelated, which can violate the independence \n",
    "assumption.\n",
    "\n",
    "\n",
    "There is a linear relationship between the predictors (x) and the outcome (y)\n",
    "Predictors (x) are independent and observed with negligible error\n",
    "Residual Errors have a mean value of zero\n",
    "Residual Errors have constant variance\n",
    "Residual Errors are independent from each other and predictors (x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using\n",
    "# a real-world scenario.\n",
    "\"\"\"The slope and intercept in a linear regression model represent the relationship between the independent variable\n",
    " and dependent variable. The slope represents the change in the dependent variable for each one-unit change in the\n",
    "   independent variable, while the intercept represents the value of the dependent variable when the independent\n",
    "     variable is equal to zero.\n",
    "\n",
    "\n",
    "\n",
    "In this real-world scenario, the slope and intercept could be interpreted as follows: Suppose we have data on the \n",
    "heights and weights of a group of people, and we fit a linear regression model to the data. If the slope of the \n",
    "model is 2.5 and the intercept is 100, we can interpret the results as follows: For each additional inch in height, \n",
    "the person's weight increases by an average of 2.5 kg. The intercept of 100 is meaningless in this scenario, \n",
    "as there are no people in the dataset with a height of zero.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4. Explain the concept of gradient descent. How is it used in machine learning?\n",
    "\"\"\"Gradient descent is an optimization algorithm used to minimize the cost function in a machine learning model. \n",
    "In machine learning, the cost function measures the difference between the predicted values and the actual values,\n",
    " and the goal is to minimize this difference.\n",
    "\n",
    "we start from any arbitary  point to evalute the performance. from that starting point , we we find the derivative at \n",
    "that point we can use the tangent line to obseve the steepness of slope , the slope will update the information about \n",
    "weight and bias . The slope at the starting point will be steeper and it will but as new parameters are generated \n",
    "the steepness will decrease untill it reaches the point of convergence.\n",
    "\n",
    "similar to finding the line of best fit in linear regression, the goal to gradient descent to minimize the cost function\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?\n",
    "\"\"\"multiple linear regression is the extension of the linear regression modeel in which there are more than one independent \n",
    "variable.\n",
    "\n",
    "\n",
    "\n",
    "The main difference between simple linear regression and multiple linear regression is the number of independent variables\n",
    " used in the model. In simple linear regression, there is only one independent variable, while in multiple linear regression,\n",
    "   there are two or more independent variables.\n",
    "\n",
    "Multiple linear regression allows us to model the relationship between a dependent variable and multiple independent\n",
    " variables. By including more independent variables in the model, we can capture more complex relationships between \n",
    " the variables and improve the accuracy of the model's predictions.\n",
    "\n",
    "\n",
    "\n",
    "To summarize, multiple linear regression is a statistical technique used to model the relationship between a dependent\n",
    " variable and two or more independent variables. It differs from simple linear regression in that it includes multiple \n",
    " independent variables in the model, allowing for more complex relationships to be captured.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and\n",
    "# address this issue?\n",
    "\"\"\"In multiple linear regression, multicollinearity refers to a situation where two or more independent variables\n",
    " are highly correlated with each other. \n",
    "\n",
    "\n",
    "\n",
    "Correlation matrix--->We will find the correlation matrix between two independent variables if the value is close to \n",
    "one then it shows that the feature is higly dependent on one another .\n",
    "\n",
    "Variance Inflation Factor ----->VIF measures the extent to which the variance of the estimated regression coefficient\n",
    " for an independent variable is increased due to multicollinearity. A VIF value greater than 5 or 10 is usually considered \n",
    " as indicating multicollinearity.\n",
    "\n",
    "how to solve the problem of multicollinearity \n",
    "\n",
    "If the value of correlation matches significantly then then one of the variables can be dropped .\n",
    "\n",
    "Another method is to combine the variables that matches significantly.\n",
    "\n",
    "The main purpose of removing the multicollinearity is to get the accurate results .\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7. Describe the polynomial regression model. How is it different from linear regression?\n",
    "\"\"\"A simple linear regression model works when the relationship is linear, but suppose we have non linear data \n",
    ", then linear regression will not be able in fitting the dataset \n",
    "Hence the polynomial linear regression is introduced so that it could best fit the data .\n",
    "\n",
    "The relationship between the dependent and the independent variable is modelled as the nth degree polynomial.\n",
    "When the polynomial is of degree 2, it is called a quadratic model; when the degree of a polynomial is 3,\n",
    " it is called a cubic model, and so on \n",
    " \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q8. What are the advantages and disadvantages of polynomial regression compared to linear\n",
    "# regression? In what situations would you prefer to use polynomial regression?\n",
    "\"\"\"Advantages of polynomial regression\n",
    "\n",
    "Better representation of non-linear relationships---> Polynomial regression can capture non-linear relationships between \n",
    "the dependent and independent variables more accurately than linear regression.\n",
    "\n",
    "Increased flexibility---> By allowing for higher-order polynomials, polynomial regression can provide greater flexibility \n",
    "in modeling complex relationships between variables.\n",
    "\n",
    "Disadvantages of polynomial regression compared to linear regression---->\n",
    "\n",
    "Overfitting----> Using a high degree polynomial equation can lead to overfitting the data, which means the model\n",
    " fits the noise in the data rather than the underlying relationship, resulting in poor generalization to new data.\n",
    "\n",
    "Increased complexity----> With an increase in the degree of the polynomial, the complexity of the model increases,\n",
    " making it more difficult to interpret and understand.\n",
    "\n",
    "\n",
    "\n",
    "Situations where polynomial regression may be preferred over linear regression----->\n",
    "\n",
    "When the relationship between the independent and dependent variables is non-linear.\n",
    "\n",
    "When a linear regression model does not fit the data well.\n",
    "\n",
    "When higher accuracy is desired, even if it comes at the cost of increased model complexity.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
